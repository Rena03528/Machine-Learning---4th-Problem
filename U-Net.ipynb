{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train_b = np.load(\"Xtrain2_b.npy\")\n",
    "Y_train_b = np.load(\"Ytrain2_b.npy\")\n",
    "\n",
    "images = X_train_b.reshape(-1, 48, 48)\n",
    "masks = Y_train_b.reshape(-1, 48, 48)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Class for In-Memory Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NumpyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for segmentation using reshaped numpy arrays.\n",
    "    \"\"\"\n",
    "    def __init__(self, images, masks, transform=None):\n",
    "        assert len(images) == len(masks), \"Images and masks should have the same length.\"\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx][np.newaxis, ...]  \n",
    "        mask = self.masks[idx][np.newaxis, ...] \n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=mask)\n",
    "            image, mask = transformed[\"image\"], transformed[\"mask\"]\n",
    "\n",
    "        return torch.tensor(image, dtype=torch.float32), torch.tensor(mask, dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-Net Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout_rate=0.1):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.Dropout(dropout_rate)  \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=2, features=[64, 128, 256, 512]):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "        \n",
    "        for feature in features:\n",
    "            self.encoder.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "            \n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n",
    "        \n",
    "        for feature in reversed(features):\n",
    "            self.decoder.append(\n",
    "                nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2)\n",
    "            )\n",
    "            self.decoder.append(DoubleConv(feature * 2, feature))\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc_feats = []\n",
    "        \n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "            enc_feats.append(x)\n",
    "            x = nn.MaxPool2d(kernel_size=2, stride=2)(x)\n",
    "        \n",
    "        x = self.bottleneck(x)\n",
    "        \n",
    "        for i in range(0, len(self.decoder), 2):\n",
    "            x = self.decoder[i](x) \n",
    "            enc_feat = enc_feats[-(i // 2 + 1)]\n",
    "\n",
    "            if x.shape != enc_feat.shape:\n",
    "                x = nn.functional.interpolate(x, size=enc_feat.shape[2:], mode=\"bilinear\", align_corners=True)\n",
    "                \n",
    "            x = torch.cat((enc_feat, x), dim=1)\n",
    "            x = self.decoder[i + 1](x) \n",
    "        \n",
    "        return self.final_conv(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        for images, masks in tqdm(train_loader, leave=True):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                outputs = model(images)\n",
    "                val_loss += criterion(outputs, masks).item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss / len(train_loader):.4f}, \"\n",
    "              f\"Val Loss: {val_loss / len(val_loader):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def check_accuracy(loader, model, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            preds = torch.sigmoid(model(images))\n",
    "            preds = (preds > 0.5).float()\n",
    "\n",
    "            true_positive += ((preds == 1) & (masks == 1)).sum().item()\n",
    "            true_negative += ((preds == 0) & (masks == 0)).sum().item()\n",
    "\n",
    "            false_positive += ((preds == 1) & (masks == 0)).sum().item()\n",
    "            false_negative += ((preds == 0) & (masks == 1)).sum().item()\n",
    "\n",
    "    sensitivity = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "    specificity = true_negative / (true_negative + false_positive) if (true_negative + false_positive) > 0 else 0\n",
    "\n",
    "    balanced_accuracy = (sensitivity + specificity) / 2\n",
    "    print(f\"Balanced Accuracy: {balanced_accuracy * 100:.2f}%\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_predictions_as_imgs(loader, model, num_images=6, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    images_shown = 0\n",
    "\n",
    "    for images, masks in loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        with torch.no_grad():\n",
    "            preds = torch.sigmoid(model(images))\n",
    "            preds = (preds > 0.5).float()\n",
    "\n",
    "        batch_size = images.shape[0]\n",
    "        for i in range(batch_size):\n",
    "            if images_shown >= num_images:\n",
    "                model.train()\n",
    "                return\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.title(\"Image\")\n",
    "            plt.imshow(images[i].cpu().squeeze(), cmap=\"gray\")\n",
    "            \n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.title(\"Prediction\")\n",
    "            plt.imshow(preds[i].cpu().squeeze(), cmap=\"gray\")\n",
    "            \n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.title(\"Ground Truth\")\n",
    "            plt.imshow(masks[i].cpu().squeeze(), cmap=\"gray\")\n",
    "            \n",
    "            plt.show()\n",
    "            images_shown += 1\n",
    "\n",
    "    model.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = NumpyDataset(X_train, Y_train)\n",
    "val_dataset = NumpyDataset(X_val, Y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "model = UNet(in_channels=1, out_channels=1)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5, device=\"cpu\")\n",
    "\n",
    "check_accuracy(val_loader, model, device=\"cpu\")\n",
    "save_predictions_as_imgs(val_loader, model, num_images=6, device=\"cpu\")\n",
    "\n",
    "torch.save(model.state_dict(), \"u-net_pytorch1.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, device=\"cpu\"):\n",
    "    model = UNet(in_channels=1, out_channels=1)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval() \n",
    "    return model\n",
    "\n",
    "model_path = \"u-net_pytorch2.pth\"\n",
    "device = \"cpu\"\n",
    "model = load_model(model_path, device=device)\n",
    "\n",
    "check_accuracy(val_loader, model, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net with class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_b = np.load(\"Xtrain2_b.npy\")  \n",
    "Y_train_b = np.load(\"Ytrain2_b.npy\")  \n",
    "\n",
    "X_train_b = X_train_b.reshape(547, 1, 48, 48)  \n",
    "Y_train_b = Y_train_b.reshape(547, 1, 48, 48) \n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_b, dtype=torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_train_b, dtype=torch.float32)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_tensor, Y_train_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-Net Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 1, kernel_size=1)  \n",
    "        )\n",
    "\n",
    "        self.final_activation = nn.Sigmoid()  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return self.final_activation(x)  \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dice Loss and Class Weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(preds, targets, epsilon=1e-6):\n",
    "    preds = preds.view(-1)\n",
    "    targets = targets.view(-1)\n",
    "    intersection = (preds * targets).sum()\n",
    "    return 1 - (2. * intersection + epsilon) / (preds.sum() + targets.sum() + epsilon)\n",
    "\n",
    "def calculate_class_weights(y):\n",
    "    y_flat = y.view(-1)\n",
    "    class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_flat.numpy()), y=y_flat.numpy())\n",
    "    return torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "class_weights = calculate_class_weights(Y_train_tensor)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights[1].to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 50\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, masks in train_loader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device).float() \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step(running_loss / len(train_loader)) \n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "val_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, masks in val_loader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device).float()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "print(f'Validation Loss: {val_loss/len(val_loader):.4f}')\n",
    "\n",
    "torch.save(model.state_dict(), \"unet_weights_with_class_weights3.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import jaccard_score, f1_score, balanced_accuracy_score, accuracy_score\n",
    "\n",
    "def evaluate_model(model, val_loader, device):\n",
    "    model.eval() \n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device).float()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            preds = (outputs > 0.5).float() \n",
    "            \n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_targets.append(masks.cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_targets = np.concatenate(all_targets, axis=0)\n",
    "\n",
    "    return all_preds, all_targets\n",
    "\n",
    "def calculate_metrics(preds, targets):\n",
    "    preds_flat = preds.flatten()\n",
    "    targets_flat = targets.flatten()\n",
    "    \n",
    "    balanced_acc = balanced_accuracy_score(targets_flat, preds_flat)\n",
    "    \n",
    "    accuracy = accuracy_score(targets_flat, preds_flat)\n",
    "\n",
    "    return balanced_acc, accuracy\n",
    "\n",
    "preds, targets = evaluate_model(model, val_loader, device)\n",
    "\n",
    "balanced_acc, accuracy = calculate_metrics(preds, targets)\n",
    "\n",
    "print(f'Balanced Accuracy: {balanced_acc:.4f}')\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_results(images, preds, targets, num_samples=5):\n",
    "    \"\"\"Visualize input images, predicted masks, and ground truth masks.\"\"\"\n",
    "    plt.figure(figsize=(15, 5 * num_samples))\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(num_samples, 3, i * 3 + 1)\n",
    "        plt.imshow(images[i].squeeze(), cmap='gray')\n",
    "        plt.title('Input Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(num_samples, 3, i * 3 + 2)\n",
    "        plt.imshow(preds[i].squeeze(), cmap='gray')\n",
    "        plt.title('Predicted Mask')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(num_samples, 3, i * 3 + 3)\n",
    "        plt.imshow(targets[i].squeeze(), cmap='gray')\n",
    "        plt.title('Ground Truth Mask')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_results(X_val, preds, y_val) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch with Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for segmentation using reshaped numpy arrays.\n",
    "    \"\"\"\n",
    "    def __init__(self, images, masks, transform=None):\n",
    "        assert len(images) == len(masks), \"Images and masks should have the same length.\"\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx][np.newaxis, ...]  \n",
    "        mask = self.masks[idx][np.newaxis, ...] \n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=mask)\n",
    "            image, mask = transformed[\"image\"], transformed[\"mask\"]\n",
    "\n",
    "        return torch.tensor(image, dtype=torch.float32), torch.tensor(mask, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout_rate=0.1):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "        \n",
    "        for feature in features:\n",
    "            self.encoder.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "            \n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n",
    "        \n",
    "        for feature in reversed(features):\n",
    "            self.decoder.append(\n",
    "                nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2)\n",
    "            )\n",
    "            self.decoder.append(DoubleConv(feature * 2, feature))\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc_feats = []\n",
    "        \n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "            enc_feats.append(x)\n",
    "            x = nn.MaxPool2d(kernel_size=2, stride=2)(x)\n",
    "        \n",
    "        x = self.bottleneck(x)\n",
    "        \n",
    "        for i in range(0, len(self.decoder), 2):\n",
    "            x = self.decoder[i](x)\n",
    "            enc_feat = enc_feats[-(i // 2 + 1)]\n",
    "\n",
    "            if x.shape != enc_feat.shape:\n",
    "                x = nn.functional.interpolate(x, size=enc_feat.shape[2:], mode=\"bilinear\", align_corners=True)\n",
    "                \n",
    "            x = torch.cat((enc_feat, x), dim=1)\n",
    "            x = self.decoder[i + 1](x)\n",
    "        \n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate pos_weight based on pixel balance\n",
    "def calculate_pos_weight(Y_train):\n",
    "    num_crater_pixels = (Y_train == 1).sum()\n",
    "    num_background_pixels = (Y_train == 0).sum()\n",
    "    pos_weight = num_background_pixels / (num_crater_pixels + 1e-6)\n",
    "    return pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        for images, masks in tqdm(train_loader, leave=True):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                outputs = model(images)\n",
    "                val_loss += criterion(outputs, masks).item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss / len(train_loader):.4f}, \"\n",
    "              f\"Val Loss: {val_loss / len(val_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate balanced accuracy\n",
    "def check_accuracy(loader, model, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            preds = torch.sigmoid(model(images))\n",
    "            preds = (preds > 0.5).float()\n",
    "\n",
    "            true_positive += ((preds == 1) & (masks == 1)).sum().item()\n",
    "            true_negative += ((preds == 0) & (masks == 0)).sum().item()\n",
    "\n",
    "            false_positive += ((preds == 1) & (masks == 0)).sum().item()\n",
    "            false_negative += ((preds == 0) & (masks == 1)).sum().item()\n",
    "\n",
    "    sensitivity = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "    specificity = true_negative / (true_negative + false_positive) if (true_negative + false_positive) > 0 else 0\n",
    "\n",
    "    balanced_accuracy = (sensitivity + specificity) / 2\n",
    "    print(f\"Balanced Accuracy: {balanced_accuracy * 100:.2f}%\")\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization function\n",
    "def save_predictions_as_imgs(loader, model, num_images=6, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    images_shown = 0\n",
    "\n",
    "    for images, masks in loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        with torch.no_grad():\n",
    "            preds = torch.sigmoid(model(images))\n",
    "            preds = (preds > 0.5).float()\n",
    "\n",
    "        batch_size = images.shape[0]\n",
    "        for i in range(batch_size):\n",
    "            if images_shown >= num_images:\n",
    "                model.train()\n",
    "                return\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.title(\"Image\")\n",
    "            plt.imshow(images[i].cpu().squeeze(), cmap=\"gray\")\n",
    "            \n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.title(\"Prediction\")\n",
    "            plt.imshow(preds[i].cpu().squeeze(), cmap=\"gray\")\n",
    "            \n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.title(\"Ground Truth\")\n",
    "            plt.imshow(masks[i].cpu().squeeze(), cmap=\"gray\")\n",
    "            \n",
    "            plt.show()\n",
    "            images_shown += 1\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = NumpyDataset(X_train, Y_train)\n",
    "val_dataset = NumpyDataset(X_val, Y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "model = UNet(in_channels=1, out_channels=1)\n",
    "\n",
    "pos_weight = calculate_pos_weight(Y_train)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight], device=\"cpu\"))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5, device=\"cpu\")\n",
    "\n",
    "check_accuracy(val_loader, model, device=\"cpu\")\n",
    "\n",
    "save_predictions_as_imgs(val_loader, model, num_images=6, device=\"cpu\")\n",
    "\n",
    "torch.save(model.state_dict(), \"u-net_pytorch_wc.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, device=\"cpu\"):\n",
    "    model = UNet(in_channels=1, out_channels=1)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval() \n",
    "    return model\n",
    "\n",
    "model_path = \"u-net_pytorch_wc.pth\"\n",
    "device = \"cpu\"\n",
    "model = load_model(model_path, device=device)\n",
    "\n",
    "check_accuracy(val_loader, model, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining Ytest2_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_predictions(X_teste, model, device=\"cpu\"):\n",
    "    num_images = X_teste.shape[0]\n",
    "\n",
    "    X_teste_reshaped = X_teste.reshape(num_images, 1, 48, 48)\n",
    "    X_teste_tensor = torch.tensor(X_teste_reshaped, dtype=torch.float32).to(device)\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_teste_tensor) \n",
    "        preds = torch.sigmoid(logits)\n",
    "        binary_preds = (preds > 0.5).float()\n",
    "\n",
    "        predictions = binary_preds.view(num_images, -1).cpu().numpy()\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def visualize_predictions_grid(predictions, num_images=16, cols=4):\n",
    "    rows = num_images // cols + (num_images % cols > 0)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(num_images):\n",
    "        axes[i].imshow(predictions[i].reshape(48, 48), cmap=\"gray\")\n",
    "        axes[i].axis(\"off\")\n",
    "        axes[i].set_title(f\"Predict {i+1}\")\n",
    "\n",
    "    for i in range(num_images, len(axes)):\n",
    "        axes[i].axis(\"off\")  # Esconde os eixos dos plots vazios, se houver\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "X_test = np.load(\"Xtest2_b.npy\")\n",
    "print(X_test.shape)\n",
    "model_path = \"u-net_pytorch_wc.pth\"\n",
    "device = \"cpu\"\n",
    "model = load_model(model_path, device=device)\n",
    "\n",
    "predictions = generate_predictions(X_test, model, device=device)\n",
    "\n",
    "np.save(\"Ytest2_b.npy\", predictions)\n",
    "\n",
    "Y_test = np.load(\"Ytest2_b.npy\")\n",
    "print(Y_test.shape)\n",
    "\n",
    "visualize_predictions_grid(predictions, num_images=16, cols=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
